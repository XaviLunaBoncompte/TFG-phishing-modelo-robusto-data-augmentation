{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41febea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELDA 1: Configuraciones básicas\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import joblib\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "%run 00_setup.ipynb\n",
    "\n",
    "#RUTAS\n",
    "from src.config.rutas import (\n",
    "    OUTPUT_DIR,\n",
    "    RUTA_DATASET,\n",
    "    RANDOM_STATE\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "#Se importan las funciones y rutas creadas en los modulos .py de /feat_aux\n",
    "from src.feat_aux import (\n",
    "    preprocesar_dataset,\n",
    "    dividir_train_test_estratificado,\n",
    "    construir_tfidf,\n",
    "    ajustar_y_vectorizar,\n",
    "    calc_dispersion,\n",
    "    guardar_meta\n",
    ")\n",
    "\n",
    "VERSION = \"eva_hard_voting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12b8fef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. de columnas y filas:\n",
      "(16127, 5)\n",
      "Forma tras preprocesar: (16126, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>label</th>\n",
       "      <th>vector</th>\n",
       "      <th>fuente</th>\n",
       "      <th>id</th>\n",
       "      <th>texto_preprocesado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Moby Pub Quiz.Win a £100 High Street prize if ...</td>\n",
       "      <td>1</td>\n",
       "      <td>sms</td>\n",
       "      <td>mendeley</td>\n",
       "      <td>0</td>\n",
       "      <td>moby pub quiz.win a 100 high street prize if u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.documenters.org</td>\n",
       "      <td>0</td>\n",
       "      <td>url</td>\n",
       "      <td>phiusiil</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.documenters.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scan system adware wrongful 6130320948821283 c...</td>\n",
       "      <td>1</td>\n",
       "      <td>email</td>\n",
       "      <td>kaggle_email</td>\n",
       "      <td>2</td>\n",
       "      <td>scan system adware wrongful 6130320948821283 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mit student thesis writeups hi vince krishna t...</td>\n",
       "      <td>0</td>\n",
       "      <td>email</td>\n",
       "      <td>kaggle_email</td>\n",
       "      <td>3</td>\n",
       "      <td>mit student thesis writeups hi vince krishna t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://swn9klhal.web.app/</td>\n",
       "      <td>1</td>\n",
       "      <td>url</td>\n",
       "      <td>phiusiil</td>\n",
       "      <td>4</td>\n",
       "      <td>https://swn9klhal.web.app/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texto  label vector  \\\n",
       "0  Moby Pub Quiz.Win a £100 High Street prize if ...      1    sms   \n",
       "1                        https://www.documenters.org      0    url   \n",
       "2  scan system adware wrongful 6130320948821283 c...      1  email   \n",
       "3  mit student thesis writeups hi vince krishna t...      0  email   \n",
       "4                         https://swn9klhal.web.app/      1    url   \n",
       "\n",
       "         fuente  id                                 texto_preprocesado  \n",
       "0      mendeley   0  moby pub quiz.win a 100 high street prize if u...  \n",
       "1      phiusiil   1                        https://www.documenters.org  \n",
       "2  kaggle_email   2  scan system adware wrongful 6130320948821283 c...  \n",
       "3  kaggle_email   3  mit student thesis writeups hi vince krishna t...  \n",
       "4      phiusiil   4                         https://swn9klhal.web.app/  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CELDA 2: Carga del dataset\n",
    "\n",
    "dt = pd.read_csv(RUTA_DATASET)\n",
    "\n",
    "print(\"Num. de columnas y filas:\")\n",
    "print(dt.shape)\n",
    "dt.head()\n",
    "\n",
    "dt_preprocesado = preprocesar_dataset(dt)       #Se aplica internamente la funcion de limpiar\n",
    "print(\"Forma tras preprocesar:\", dt_preprocesado.shape)\n",
    "dt_preprocesado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2cbaf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (12900, 6)\n",
      "Test: (3226, 6)\n",
      "\n",
      "Distribucion por clases (train):\n",
      "label\n",
      "0    7200\n",
      "1    5700\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "label\n",
      "0    0.55814\n",
      "1    0.44186\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribucion por clases (test):\n",
      "label\n",
      "0    1800\n",
      "1    1426\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "label\n",
      "0    0.557967\n",
      "1    0.442033\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribucion por vector (train):\n",
      "vector\n",
      "url      4800\n",
      "email    4799\n",
      "sms      3301\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "\n",
      "Distribucion por vector (test):\n",
      "vector\n",
      "email    1200\n",
      "url      1200\n",
      "sms       826\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CELDA 3: Division estratificada train/test\n",
    "\n",
    "dt_train, dt_test = dividir_train_test_estratificado(dt_preprocesado)\n",
    "\n",
    "print(\"Train:\", dt_train.shape)\n",
    "print(\"Test:\", dt_test.shape)\n",
    "\n",
    "print(\"\\nDistribucion por clases (train):\")\n",
    "print(dt_train[\"label\"].value_counts(), \"\\n\")\n",
    "print(dt_train[\"label\"].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDistribucion por clases (test):\")\n",
    "print(dt_test[\"label\"].value_counts(), \"\\n\")\n",
    "print(dt_test[\"label\"].value_counts(normalize=True))\n",
    "\n",
    "\n",
    "print(\"\\nDistribucion por vector (train):\")\n",
    "print(dt_train[\"vector\"].value_counts(), \"\\n\")\n",
    "\n",
    "print(\"\\nDistribucion por vector (test):\")\n",
    "print(dt_test[\"vector\"].value_counts(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c5d5c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (12900, 22675)\n",
      "x_test: (3226, 22675)\n",
      "Etiquetas unicas: [0 1]\n",
      "\n",
      "Guardando metadatos en: C:\\TFG\\models\\preprocesamiento_metadata_eva_hard_voting.json\n",
      "Artefactos guardados\n",
      "Vectorizador: C:\\TFG\\models\\tfidf_vect_eva_hard_voting.joblib\n",
      "Train: C:\\TFG\\models\\train_eva_hard_voting.csv\n",
      "Test: C:\\TFG\\models\\test_eva_hard_voting.csv\n",
      "Meta: C:\\TFG\\models\\preprocesamiento_metadata_eva_hard_voting.json\n"
     ]
    }
   ],
   "source": [
    "#CELDA 4: Contruccion de TF_IDF y posterior ajuste\n",
    "\n",
    "tfidf = construir_tfidf(\n",
    "    ngram_range=(1, 2),\n",
    "    min_dt=5,\n",
    "    max_dt=0.9,\n",
    "    max_features=50000\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = ajustar_y_vectorizar(tfidf, dt_train, dt_test)\n",
    "\n",
    "print(\"x_train:\", x_train.shape)\n",
    "print(\"x_test:\", x_test.shape)\n",
    "print(\"Etiquetas unicas:\", np.unique(y_train))\n",
    "\n",
    "guardar_meta(tfidf, dt_train, dt_test, OUTPUT_DIR, version=VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "060f62ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispersion del train: 0.9980\n",
      "Dispersion del test: 0.9981\n"
     ]
    }
   ],
   "source": [
    "#CELDA 5: Dispersion de las matrices\n",
    "\n",
    "disp_train = calc_dispersion(x_train)\n",
    "disp_test = calc_dispersion(x_test)\n",
    "\n",
    "print(f\"Dispersion del train: {disp_train:.4f}\")\n",
    "print(f\"Dispersion del test: {disp_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3a9cb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".: SVM :.\n",
      "Accuracy: 0.9768\n",
      "Precison: 0.9768\n",
      "Recall: 0.9760\n",
      "F1-macro: 0.9764\n",
      "F1-weighted: 0.9767\n",
      "\n",
      "Report de clasificación SVM:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1800\n",
      "           1       0.98      0.97      0.97      1426\n",
      "\n",
      "    accuracy                           0.98      3226\n",
      "   macro avg       0.98      0.98      0.98      3226\n",
      "weighted avg       0.98      0.98      0.98      3226\n",
      "\n",
      "\n",
      "Matriz de confusion:\n",
      "\n",
      "[[1768   32]\n",
      " [  43 1383]]\n"
     ]
    }
   ],
   "source": [
    "#CELDA 6: Entrenamiento del modelo SVM:\n",
    "\n",
    "svm = LinearSVC(\n",
    "    class_weight=\"balanced\",         #considera el desbalance que hay y penaliza los errores en las clases minoritarias\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "#Se entrena el modelo\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "#Se genera la prediccion\n",
    "y_pred_xtest_svm = svm.predict(x_test)\n",
    "\n",
    "#Metricas\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_xtest_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_xtest_svm, average=\"macro\", zero_division=0)\n",
    "recall_svm = recall_score(y_test, y_pred_xtest_svm, average=\"macro\", zero_division=0)\n",
    "f1_mac_svm = f1_score(y_test, y_pred_xtest_svm, average=\"macro\", zero_division=0)       #Calcula f1 equitativamente cada clase\n",
    "f1_wei_svm = f1_score(y_test, y_pred_xtest_svm, average=\"weighted\", zero_division=0)    #Calcula f1 segun la frecuencia real\n",
    "\n",
    "print(\".: SVM :.\")\n",
    "print(f\"Accuracy: {accuracy_svm:.4f}\")\n",
    "print(f\"Precison: {precision_svm:.4f}\")\n",
    "print(f\"Recall: {recall_svm:.4f}\")\n",
    "print(f\"F1-macro: {f1_mac_svm:.4f}\")\n",
    "print(f\"F1-weighted: {f1_wei_svm:.4f}\")\n",
    "\n",
    "#Se muestra un reporte conjunto\n",
    "print(\"\\nReport de clasificación SVM:\\n\")\n",
    "print(classification_report(y_test, y_pred_xtest_svm, zero_division=0))\n",
    "\n",
    "#Muestra una tabla de predicciones que fueron segun TP, TN, FP, FN\n",
    "print(\"\\nMatriz de confusion:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_xtest_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd94f6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.58363387\n",
      "Validation score: 0.947287\n",
      "Iteration 2, loss = 0.20899391\n",
      "Validation score: 0.965116\n",
      "Iteration 3, loss = 0.10955170\n",
      "Validation score: 0.965891\n",
      "Iteration 4, loss = 0.09265796\n",
      "Validation score: 0.966667\n",
      "Iteration 5, loss = 0.08412127\n",
      "Validation score: 0.967442\n",
      "Iteration 6, loss = 0.07818920\n",
      "Validation score: 0.965891\n",
      "Iteration 7, loss = 0.07382743\n",
      "Validation score: 0.968992\n",
      "Iteration 8, loss = 0.06893742\n",
      "Validation score: 0.968992\n",
      "Iteration 9, loss = 0.06423078\n",
      "Validation score: 0.964341\n",
      "Iteration 10, loss = 0.05923172\n",
      "Validation score: 0.968217\n",
      "Iteration 11, loss = 0.05521229\n",
      "Validation score: 0.970543\n",
      "Iteration 12, loss = 0.05058528\n",
      "Validation score: 0.968992\n",
      "Iteration 13, loss = 0.04644050\n",
      "Validation score: 0.971318\n",
      "Iteration 14, loss = 0.04300472\n",
      "Validation score: 0.971318\n",
      "Iteration 15, loss = 0.03843515\n",
      "Validation score: 0.968992\n",
      "Iteration 16, loss = 0.03538009\n",
      "Validation score: 0.971318\n",
      "Iteration 17, loss = 0.03190343\n",
      "Validation score: 0.972093\n",
      "Iteration 18, loss = 0.02994885\n",
      "Validation score: 0.971318\n",
      "Iteration 19, loss = 0.02752480\n",
      "Validation score: 0.971318\n",
      "Iteration 20, loss = 0.02477992\n",
      "Validation score: 0.968217\n",
      "Iteration 21, loss = 0.02389521\n",
      "Validation score: 0.969767\n",
      "Validation score did not improve more than tol=0.000100 for 3 consecutive epochs. Stopping.\n",
      "\n",
      ".: MLP :.\n",
      "Accuracy: 0.9740\n",
      "Precison: 0.9740\n",
      "Recall: 0.9732\n",
      "F1-macro: 0.9736\n",
      "F1-weighted: 0.9740\n",
      "AUC-ROC: 0.9938\n",
      "\n",
      "Report de clasificación MLP:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      1800\n",
      "           1       0.97      0.97      0.97      1426\n",
      "\n",
      "    accuracy                           0.97      3226\n",
      "   macro avg       0.97      0.97      0.97      3226\n",
      "weighted avg       0.97      0.97      0.97      3226\n",
      "\n",
      "\n",
      "Matriz de confusion:\n",
      "\n",
      "[[1763   37]\n",
      " [  47 1379]]\n"
     ]
    }
   ],
   "source": [
    "#CELDA 7: Entrenamiento del modelo MLP\n",
    "\n",
    "#Se reduce la dimensionalidad sobre TF-IDF para no saturar el sistema al depender de mucha RAM. De esta manera es reproducible\n",
    "svd = TruncatedSVD(n_components=300, random_state=RANDOM_STATE)\n",
    "\n",
    "#Se transforma la matrix dispersa en completa\n",
    "x_train_reducido = svd.fit_transform(x_train)\n",
    "x_test_reducido = svd.transform(x_test)\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64),       #Define la estructura de la red neuronal siendo densamente conectada con 128 neuronas en la primera capa y 64 neuronas en la segunda\n",
    "    activation=\"relu\",                  #Activacion estandar para la mayoria de los modelos\n",
    "    solver=\"adam\",                      #Se pasa el optimizador mas recomendado para NLP\n",
    "    random_state=RANDOM_STATE,\n",
    "    max_iter=40,                        #Se define un maximo de 40 iteraciones para entrenar la red\n",
    "    early_stopping=True,                #Activa la parada temprana\n",
    "    n_iter_no_change=3,                 #Si en 3 iteraciones el modelo no mejora la perdida de validacion, se detiene automaticamente.\n",
    "    verbose=True                        #Imprime la informacion durante el entrenamiento para visualizar resultados de las iteraciones\n",
    ")\n",
    "\n",
    "#Se entrena el modelo\n",
    "mlp.fit(x_train_reducido, y_train)\n",
    "\n",
    "#Se genera la prediccion\n",
    "y_pred_xtest_mlp = mlp.predict(x_test_reducido)\n",
    "y_prob_xtest_mlp = mlp.predict_proba(x_test_reducido) [:, 1]\n",
    "\n",
    "#Metricas\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred_xtest_mlp)\n",
    "precision_mlp = precision_score(y_test, y_pred_xtest_mlp, average=\"macro\", zero_division=0)\n",
    "recall_mlp = recall_score(y_test, y_pred_xtest_mlp, average=\"macro\", zero_division=0)\n",
    "f1_mac_mlp = f1_score(y_test, y_pred_xtest_mlp, average=\"macro\", zero_division=0)       #Calcula f1 equitativamente cada clase\n",
    "f1_wei_mlp = f1_score(y_test, y_pred_xtest_mlp, average=\"weighted\", zero_division=0)    #Calcula f1 segun la frecuanecia real\n",
    "auc_mlp = roc_auc_score(y_test, y_prob_xtest_mlp)\n",
    "\n",
    "print(\"\\n.: MLP :.\")\n",
    "print(f\"Accuracy: {accuracy_mlp:.4f}\")\n",
    "print(f\"Precison: {precision_mlp:.4f}\")\n",
    "print(f\"Recall: {recall_mlp:.4f}\")\n",
    "print(f\"F1-macro: {f1_mac_mlp:.4f}\")\n",
    "print(f\"F1-weighted: {f1_wei_mlp:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_mlp:.4f}\")\n",
    "\n",
    "print(\"\\nReport de clasificación MLP:\\n\")\n",
    "print(classification_report(y_test, y_pred_xtest_mlp, zero_division=0))\n",
    "\n",
    "print(\"\\nMatriz de confusion:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_xtest_mlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76b43b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.58363387\n",
      "Validation score: 0.947287\n",
      "Iteration 2, loss = 0.20899391\n",
      "Validation score: 0.965116\n",
      "Iteration 3, loss = 0.10955170\n",
      "Validation score: 0.965891\n",
      "Iteration 4, loss = 0.09265796\n",
      "Validation score: 0.966667\n",
      "Iteration 5, loss = 0.08412127\n",
      "Validation score: 0.967442\n",
      "Iteration 6, loss = 0.07818920\n",
      "Validation score: 0.965891\n",
      "Iteration 7, loss = 0.07382743\n",
      "Validation score: 0.968992\n",
      "Iteration 8, loss = 0.06893742\n",
      "Validation score: 0.968992\n",
      "Iteration 9, loss = 0.06423078\n",
      "Validation score: 0.964341\n",
      "Iteration 10, loss = 0.05923172\n",
      "Validation score: 0.968217\n",
      "Iteration 11, loss = 0.05521229\n",
      "Validation score: 0.970543\n",
      "Iteration 12, loss = 0.05058528\n",
      "Validation score: 0.968992\n",
      "Iteration 13, loss = 0.04644050\n",
      "Validation score: 0.971318\n",
      "Iteration 14, loss = 0.04300472\n",
      "Validation score: 0.971318\n",
      "Iteration 15, loss = 0.03843515\n",
      "Validation score: 0.968992\n",
      "Iteration 16, loss = 0.03538009\n",
      "Validation score: 0.971318\n",
      "Iteration 17, loss = 0.03190343\n",
      "Validation score: 0.972093\n",
      "Iteration 18, loss = 0.02994885\n",
      "Validation score: 0.971318\n",
      "Iteration 19, loss = 0.02752480\n",
      "Validation score: 0.971318\n",
      "Iteration 20, loss = 0.02477992\n",
      "Validation score: 0.968217\n",
      "Iteration 21, loss = 0.02389521\n",
      "Validation score: 0.969767\n",
      "Validation score did not improve more than tol=0.000100 for 3 consecutive epochs. Stopping.\n",
      "\n",
      ".: HARD VOTING :.\n",
      "Accuracy: 0.9749\n",
      "Precison: 0.9761\n",
      "Recall: 0.9731\n",
      "F1-macro: 0.9745\n",
      "F1-weighted: 0.9749\n",
      "\n",
      "Report de clasificación HARD VOTING:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1800\n",
      "           1       0.98      0.96      0.97      1426\n",
      "\n",
      "    accuracy                           0.97      3226\n",
      "   macro avg       0.98      0.97      0.97      3226\n",
      "weighted avg       0.98      0.97      0.97      3226\n",
      "\n",
      "\n",
      "Matriz de confusion:\n",
      "\n",
      "[[1779   21]\n",
      " [  60 1366]]\n"
     ]
    }
   ],
   "source": [
    "#CELDA 8: Hard voting\n",
    "\n",
    "#Define una pipeline que encadena varios pasos, en este caso la reduccion de la dimensionalidad y el modelo MLP\n",
    "mlp_pipeline = Pipeline([\n",
    "    (\"svd\", TruncatedSVD(n_components=300, random_state=RANDOM_STATE)),\n",
    "    (\"mlp\", MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    max_iter=40,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=3,\n",
    "    verbose=True\n",
    "    ))\n",
    "])\n",
    "\n",
    "#Se crea el modelo en ensamblado que combina ambos modelos (SVM y MLP)\n",
    "ens = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"svm\", svm),\n",
    "        (\"mlp\", mlp_pipeline)\n",
    "    ],\n",
    "    voting=\"hard\"\n",
    ")\n",
    "\n",
    "ens.fit(x_train, y_train)\n",
    "\n",
    "y_pred_xtest_ens = ens.predict(x_test)\n",
    "\n",
    "#Metricas\n",
    "accuracy_ens = accuracy_score(y_test, y_pred_xtest_ens)\n",
    "precision_ens = precision_score(y_test, y_pred_xtest_ens, average=\"macro\", zero_division=0)\n",
    "recall_ens = recall_score(y_test, y_pred_xtest_ens, average=\"macro\", zero_division=0)\n",
    "f1_mac_ens = f1_score(y_test, y_pred_xtest_ens, average=\"macro\", zero_division=0)       #Calcula f1 equitativamente cada clase\n",
    "f1_wei_ens = f1_score(y_test, y_pred_xtest_ens, average=\"weighted\", zero_division=0)    #Calcula f1 segun la frecuanecia real\n",
    "\n",
    "print(\"\\n.: HARD VOTING :.\")\n",
    "print(f\"Accuracy: {accuracy_ens:.4f}\")\n",
    "print(f\"Precison: {precision_ens:.4f}\")\n",
    "print(f\"Recall: {recall_ens:.4f}\")\n",
    "print(f\"F1-macro: {f1_mac_ens:.4f}\")\n",
    "print(f\"F1-weighted: {f1_wei_ens:.4f}\")\n",
    "\n",
    "print(\"\\nReport de clasificación HARD VOTING:\\n\")\n",
    "print(classification_report(y_test, y_pred_xtest_ens, zero_division=0))\n",
    "\n",
    "print(\"\\nMatriz de confusion:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_xtest_ens))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0ed5242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d3192\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d3192_level0_col0\" class=\"col_heading level0 col0\" >Modelo</th>\n",
       "      <th id=\"T_d3192_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_d3192_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_d3192_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_d3192_level0_col4\" class=\"col_heading level0 col4\" >F1-macro</th>\n",
       "      <th id=\"T_d3192_level0_col5\" class=\"col_heading level0 col5\" >F1-weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d3192_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d3192_row0_col0\" class=\"data row0 col0\" >SVM</td>\n",
       "      <td id=\"T_d3192_row0_col1\" class=\"data row0 col1\" >0.9768</td>\n",
       "      <td id=\"T_d3192_row0_col2\" class=\"data row0 col2\" >0.9768</td>\n",
       "      <td id=\"T_d3192_row0_col3\" class=\"data row0 col3\" >0.9760</td>\n",
       "      <td id=\"T_d3192_row0_col4\" class=\"data row0 col4\" >0.9764</td>\n",
       "      <td id=\"T_d3192_row0_col5\" class=\"data row0 col5\" >0.9767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3192_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d3192_row1_col0\" class=\"data row1 col0\" >MLP</td>\n",
       "      <td id=\"T_d3192_row1_col1\" class=\"data row1 col1\" >0.9740</td>\n",
       "      <td id=\"T_d3192_row1_col2\" class=\"data row1 col2\" >0.9740</td>\n",
       "      <td id=\"T_d3192_row1_col3\" class=\"data row1 col3\" >0.9732</td>\n",
       "      <td id=\"T_d3192_row1_col4\" class=\"data row1 col4\" >0.9736</td>\n",
       "      <td id=\"T_d3192_row1_col5\" class=\"data row1 col5\" >0.9740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3192_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d3192_row2_col0\" class=\"data row2 col0\" >Ensemble (Hard Voting)</td>\n",
       "      <td id=\"T_d3192_row2_col1\" class=\"data row2 col1\" >0.9749</td>\n",
       "      <td id=\"T_d3192_row2_col2\" class=\"data row2 col2\" >0.9761</td>\n",
       "      <td id=\"T_d3192_row2_col3\" class=\"data row2 col3\" >0.9731</td>\n",
       "      <td id=\"T_d3192_row2_col4\" class=\"data row2 col4\" >0.9745</td>\n",
       "      <td id=\"T_d3192_row2_col5\" class=\"data row2 col5\" >0.9749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26a8683cee0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CELDA 9: Comparativa SVM vs MLP vs Ensemble\n",
    "\n",
    "comparacion_modelos = pd.DataFrame({\n",
    "    \"Modelo\": [\"SVM\", \"MLP\", \"Ensemble (Hard Voting)\"],\n",
    "    \"Accuracy\": [float(accuracy_svm), float(accuracy_mlp), float(accuracy_ens)],\n",
    "    \"Precision\": [float(precision_svm), float(precision_mlp), float(precision_ens)],\n",
    "    \"Recall\": [float(recall_svm), float(recall_mlp), float(recall_ens)],\n",
    "    \"F1-macro\": [float(f1_mac_svm), float(f1_mac_mlp), float(f1_mac_ens)],\n",
    "    \"F1-weighted\": [float(f1_wei_svm), float(f1_wei_mlp), float(f1_wei_ens)],\n",
    "})\n",
    "\n",
    "cols_metricas = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-macro\", \"F1-weighted\"]\n",
    "\n",
    "comparacion_modelos.style.format(\n",
    "    {col: \"{:.4f}\" for col in cols_metricas}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49dad1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos guardados:\n",
      "SVM: C:\\TFG\\models\\modelo_svm_eva_hard_voting.joblib\n",
      "MLP: C:\\TFG\\models\\modelo_svm_eva_hard_voting.joblib\n",
      "Ensamble: C:\\TFG\\models\\modelo_ens_eva_hard_voting.joblib\n"
     ]
    }
   ],
   "source": [
    "#CELDA 10: Guardado de los modelos finales\n",
    "\n",
    "svm_path = OUTPUT_DIR / f\"modelo_svm_{VERSION}.joblib\"\n",
    "mlp_path = OUTPUT_DIR / f\"modelo_mlp_{VERSION}.joblib\"\n",
    "ens_path = OUTPUT_DIR / f\"modelo_ens_{VERSION}.joblib\"\n",
    "\n",
    "joblib.dump(svm, svm_path)\n",
    "joblib.dump(mlp, mlp_path)\n",
    "joblib.dump(ens, ens_path)\n",
    "\n",
    "print(\"Modelos guardados:\")\n",
    "print(\"SVM:\", svm_path)\n",
    "print(\"MLP:\", svm_path)\n",
    "print(\"Ensamble:\", ens_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1218ef0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metricas guardadas en: C:\\TFG\\models\\metricas_modelos_eva_hard_voting.json\n"
     ]
    }
   ],
   "source": [
    "#CELDA 11: Guardar metricas en JSON\n",
    "\n",
    "metricas = {\n",
    "        \"version\": VERSION,\n",
    "        \"generated_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"modelos\": {\n",
    "            \"SVM\": {\n",
    "                \"accuracy\": float(accuracy_svm),\n",
    "                \"precision\": float(precision_svm),\n",
    "                \"recall\": float(recall_svm),\n",
    "                \"F1-macro\": float(f1_mac_svm),\n",
    "                \"F1-weighted\": float(f1_wei_svm),\n",
    "                \"model_path\": str(svm_path)\n",
    "            },\n",
    "            \"MLP\": {\n",
    "                \"accuracy\": float(accuracy_mlp),\n",
    "                \"precision\": float(precision_mlp),\n",
    "                \"recall\": float(recall_mlp),\n",
    "                \"F1-macro\": float(f1_mac_mlp),\n",
    "                \"F1-weighted\": float(f1_wei_mlp),\n",
    "                \"model_path\": str(mlp_path)\n",
    "            },\n",
    "            \"Ensamble\": {\n",
    "                \"accuracy\": float(accuracy_ens),\n",
    "                \"precision\": float(precision_ens),\n",
    "                \"recall\": float(recall_ens),\n",
    "                \"F1-macro\": float(f1_mac_ens),\n",
    "                \"F1-weighted\": float(f1_wei_ens),\n",
    "                \"model_path\": str(ens_path)\n",
    "            }\n",
    "        },\n",
    "        \"dispersion\": {\n",
    "            \"train\": float(disp_train),\n",
    "            \"test\": float(disp_test)\n",
    "        }\n",
    "}\n",
    "\n",
    "#Guarda el archivo JSON con todas las metricas al abrirlo en modo escritura \"w\"\n",
    "metricas_path = OUTPUT_DIR / f\"metricas_modelos_{VERSION}.json\"\n",
    "with open(metricas_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metricas, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"Metricas guardadas en:\", metricas_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
